{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Байесовский подход к оценке А/Б-тестов: сравнение выручки  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание**\n",
    "- Введение\n",
    "-- Пример теста\n",
    "-- Пример данных\n",
    "-- Разные уровни моделей и сравнения\n",
    "- Генерация данных покупок\n",
    "- Моделирование и сравнение средних выручек на пользователя\n",
    "- Моделирование и сравение распределений выручки на пользователя\n",
    "- Моделирование и сравнение покупок пользователей\n",
    "- Заключение\n",
    "- Благодарности\n",
    "- Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме конверсий нужно оценивать выручку.\n",
    "Или величины вроде длительности просмотра.\n",
    "\n",
    "\"Конверсиями зарплату не заплатишь\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ситуация примерно такая:\n",
    "пришло N пользователей, каждый совершил k покупок, у каждой покупки своя стоимость.\n",
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "    {'experiment_group': 'A', 'user_id': 1, 'timestamp': '01.01.2021 10:00:00', 'purchase_value_usd': 5},\n",
    "    {'experiment_group': 'B', 'user_id': 2, 'timestamp': '01.01.2021 10:05:00', 'purchase_value_usd': 3},\n",
    "    {'experiment_group': 'A', 'user_id': 1, 'timestamp': '01.01.2021 10:06:00', 'purchase_value_usd': 10},\n",
    "    {'experiment_group': 'A', 'user_id': 3, 'timestamp': '01.01.2021 10:07:00', 'purchase_value_usd': 5},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило интересует, в какой группе будет выше прибыль относительно потраченных на маркетинг денег.\n",
    "\n",
    "Если трафик в группах более-менее одинаковый, то можно сравнивать среднюю выручку на пользователя.  \n",
    "Иногда - выручку на сессию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий подход примерно такой же, как в случае конверсий.  \n",
    "Выбирается модель.  \n",
    "Вычисляется распределение параметров.  \n",
    "Делается оценка и сравнение интересующих метрик в группах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве основной метрики будет использоваться выручка на пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно строить модель на разном уровне детализации.\n",
    "\n",
    "Попытаться промоделировать процесс покупок.\n",
    "Т.е. для каждого пользователя делать предсказание отдельных покупок.\n",
    "Можно смотреть время между покупками.\n",
    "Можно ограничиться количеством и суммой каждой из покупок.\n",
    "\n",
    "Можно не детализировать модель до уровня покупок.\n",
    "Строить распределение суммарной выручки на пользоователя (LTV).\n",
    "\n",
    "Наконец, можно построить модель для оценки средних значений чеков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последний вариант - модель для оценки средней выручки на пользователя - кажется требующей меньше всего предположений. Можно начать с нее.\n",
    "\n",
    "\n",
    "Если выполнены условия центральной предельной теоремы, то средние значения выборок из распределения распределены нормально.\n",
    "Поэтому средний чек на пользователя можно моделировать нормальным распределением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Центральная предельная теорема."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, для распределения Парето:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pareto pdf = b / x^(b+1), b>0, x>=1\n",
    "# lomax pdf = c / (x+1)^c, c>0, x>=1 (pareto with loc=-1)\n",
    "lomax_x = np.linspace(0, 10, 100)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=lomax_x, y=stats.pareto.pdf(lomax_x, 3.5, loc=-1), name='pareto from 0, a=3.5'))\n",
    "fig.add_trace(go.Scatter(x=lomax_x, y=stats.pareto.pdf(lomax_x, 1.5, loc=-1), name='pareto from 0, a=1.5'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3000\n",
    "n_points_in_sample = 10000\n",
    "\n",
    "results = np.random.pareto(1.5, size=[n_samples, n_points_in_sample])\n",
    "\n",
    "means = np.array(list(map(np.mean, results)))\n",
    "#means\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means, nbinsx=1000))\n",
    "#fig.add_trace(go.Histogram(x=means[means<10], nbinsx=1000))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3000\n",
    "n_points_in_sample = 10000\n",
    "\n",
    "results = np.random.pareto(3.5, size=[n_samples, n_points_in_sample])\n",
    "\n",
    "means = np.array(list(map(np.mean, results)))\n",
    "#means\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means, nbinsx=100))\n",
    "#fig.add_trace(go.Histogram(x=means[means<10], nbinsx=1000))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У распределения Парето с параметром $1 \\lt a \\le 2$ дисперсия не конечная.\n",
    "Центральная предельная теорема как раз требует от распределения \n",
    "определенного значения среднего и конечного значения дисперсии.\n",
    "\n",
    "Но вроде есть обобщение центральной предельной теоремы на случай \n",
    "медленно убывающих распределений типа Парето.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель\n",
    "Пришло N пользователей.\n",
    "Каждый совершил от 0 до (бесконечности) покупок; \n",
    "предположим, что покупки независимы (что вряд ли) и вероятность каждой покупки p.\n",
    "Чек каждой покупки - 3, 5, 10, 20$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество покупок одним пользователем задается биномиальным распределением с числом попыток $n \\to \\infty$.  \n",
    "Вероятность покупки $p$ также снижается.  \n",
    "Это распределение Пуассона (https://en.wikipedia.org/wiki/Binomial_distribution#Poisson_approximation).  \n",
    "Чек каждой покупки выбирается случайно.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3000\n",
    "n_pur_users = np.random.poisson(lam=1.5, size=n)\n",
    "checks = [3, 5, 10, 20]\n",
    "\n",
    "pur_sums = np.array(list(map(lambda npur: np.sum(np.random.choice(checks, npur, replace=True)), n_pur_users)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=pur_sums, nbinsx=100))\n",
    "#fig.add_trace(go.Histogram(x=means[means<10], nbinsx=1000))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1000\n",
    "n_users = 3000\n",
    "n_pur_users = np.random.poisson(lam=1.5, size=[n_trials, n_users])\n",
    "\n",
    "checks = [3, 5, 10, 20]\n",
    "\n",
    "pur_sums = []\n",
    "for trial in n_pur_users:\n",
    "    pur_sums.append(np.array([np.sum(np.random.choice(checks, npur, replace=True)) for npur in trial]))\n",
    "#pur_sums\n",
    "\n",
    "mean_sums = [np.mean(x) for x in pur_sums]\n",
    "#mean_sums\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=mean_sums, nbinsx=50))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(pur_sums, axis=0), nbinsx=100))\n",
    "#fig.add_trace(go.Histogram(x=means[means<10], nbinsx=1000))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=mean_sums, nbinsx=100))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моделирование среднего чека по одному среднему значению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть выборка пользователей с покупками.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "checks = [3, 5, 10, 20]\n",
    "\n",
    "n_pur_users_a = np.random.poisson(lam=1.5, size=n)\n",
    "pur_sums_a = np.array(list(map(lambda npur: np.sum(np.random.choice(checks, npur, replace=True)), n_pur_users_a)))\n",
    "\n",
    "n_pur_users_b = np.random.poisson(lam=1.7, size=n)\n",
    "pur_sums_b = np.array(list(map(lambda npur: np.sum(np.random.choice(checks, npur, replace=True)), n_pur_users_b)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=pur_sums_a, nbinsx=100, name='A'))\n",
    "fig.add_trace(go.Histogram(x=pur_sums_b, nbinsx=100, name='B'))\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.5)\n",
    "#fig.add_trace(go.Histogram(x=means[means<10], nbinsx=1000))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Box(x=pur_sums_a, name='A'))\n",
    "# fig.add_trace(go.Box(x=pur_sums_b, name='B'))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_a = np.mean(pur_sums_a)\n",
    "mean_b = np.mean(pur_sums_b)\n",
    "print(mean_a, mean_b)\n",
    "\n",
    "print(np.std(pur_sums_a) / np.sqrt(len(pur_sums_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормальное распределение задается двумя параметрами - среднее и стандартное отклонение.\n",
    "Можно задать сетку из двух параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = 1001\n",
    "mean_grid = np.linspace(10, 20, grid_points) #todo: use mean_a\n",
    "mean_grid_prior = [ 1.0 / grid_points for x in mean_grid]\n",
    "grid_points = 301\n",
    "sigma_grid = np.linspace(0.001, 0.05, grid_points)\n",
    "sigma_grid_prior = [ 1.0 / grid_points for x in sigma_grid]\n",
    "\n",
    "grid = pd.merge(pd.DataFrame({'mean': mean_grid, 'mean_prior': mean_grid_prior, 'tmp_merge_key': 0}),\n",
    "                pd.DataFrame({'sigma': sigma_grid, 'sigma_prior': sigma_grid_prior, 'tmp_merge_key': 0}),\n",
    "                how='outer', \n",
    "                on='tmp_merge_key')\n",
    "grid = grid[['mean', 'sigma', 'mean_prior', 'sigma_prior']]\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['A(data|mean, sigma)'] = grid.apply(\n",
    "    lambda row: stats.norm.pdf(mean_a, loc=row['mean'], scale=row['sigma']),\n",
    "    axis = 1)\n",
    "grid['A_posterior'] = grid['A(data|mean, sigma)'] * grid['mean_prior'] * grid['sigma_prior']\n",
    "grid['A_posterior'] = grid['A_posterior'] / sum(grid['A_posterior'])\n",
    "\n",
    "grid['B(data|mean, sigma)'] = grid.apply(\n",
    "    lambda row: stats.norm.pdf(mean_b, loc=row['mean'], scale=row['sigma']),\n",
    "    axis = 1)\n",
    "grid['B_posterior'] = grid['B(data|mean, sigma)'] * grid['mean_prior'] * grid['sigma_prior']\n",
    "grid['B_posterior'] = grid['B_posterior'] / sum(grid['B_posterior'])\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: avoid overlapping scales\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(z=grid['A_posterior'],\n",
    "                         x=grid['mean'],\n",
    "                         y=grid['sigma'],\n",
    "                         opacity=0.5))\n",
    "fig.add_trace(go.Heatmap(z=grid['B_posterior'],\n",
    "                         x=grid['mean'],\n",
    "                         y=grid['sigma'],\n",
    "                         opacity=0.5))\n",
    "fig.update_layout(title='Posterior Probability Density',\n",
    "                  xaxis_title='Mean',\n",
    "                  yaxis_title='Sigma')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бутстрап\n",
    "\n",
    "Кажется, что строить модель по одной точке не очень надежно.  \n",
    "Но других точек нет.  \n",
    "\n",
    "Можно попробовать использовать бутстрап, чтобы нагенерировать еще точек.  \n",
    "Непонятно, к чему это может привести, и как это скажется на точности.  \n",
    "Но кажется, что катастрофических изменений быть не должно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jackknife_means\n",
    "\n",
    "jk_means_a = [(mean_a * len(pur_sums_a) - x) / (len(pur_sums_a) - 1)  for x in pur_sums_a]\n",
    "jk_means_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=jk_means_a, nbinsx=100))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap means\n",
    "bs_trials = 10000 \n",
    "\n",
    "bs_means_a = [np.mean(np.random.choice(pur_sums_a, len(pur_sums_a), replace=True)) for i in range(bs_trials)]\n",
    "bs_means_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=bs_means_a, nbinsx=100))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid['A logprob(data|mean, sigma)'] = grid.apply(\n",
    "#     lambda row: np.sum(stats.norm.logpdf(bs_means_a, loc=row['mean'], scale=row['sigma'])),\n",
    "#     axis = 1)\n",
    "# grid['A_posterior_log'] = grid['A logprob(data|mean, sigma)'] + np.log(grid['mean_prior'] * grid['sigma_prior'])\n",
    "# grid['A_posterior_log_norm'] = grid['A_posterior_log'] - np.sum(grid['A_posterior_log'])\n",
    "# grid['A_posterior'] = grid['A_posterior_log_norm'].apply('exp') \n",
    "# grid.head()\n",
    "\n",
    "grid['A prob(data|mean, sigma)'] = grid.apply(\n",
    "     lambda row: np.prod(stats.norm.pdf(bs_means_a, loc=row['mean'], scale=row['sigma'])),\n",
    "     axis = 1)\n",
    "grid['A_posterior'] = grid['A prob(data|mean, sigma)'] * grid['mean_prior'] * grid['sigma_prior']\n",
    "grid['A_posterior_norm'] = grid['A_posterior'] / np.sum(grid['A_posterior'])\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: avoid overlapping scales\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(z=grid['A_posterior'],\n",
    "                         x=grid['mean'],\n",
    "                         y=grid['sigma'],\n",
    "                         opacity=0.5))\n",
    "fig.add_trace(go.Heatmap(z=grid['B_posterior'],\n",
    "                         x=grid['mean'],\n",
    "                         y=grid['sigma'],\n",
    "                         opacity=0.5))\n",
    "fig.update_layout(title='Posterior Probability Density',\n",
    "                  xaxis_title='Mean',\n",
    "                  yaxis_title='Sigma')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известно, что средние в пределе описываются нормальным распределением с параметрами \n",
    "$(\\mu, \\sigma^2/\\sqrt{N})$. Есть ощущение, что вместо бутстрапа можно было бы насэмлить точек из этого распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналитическое выражение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Conjugate_prior\n",
    "\n",
    "В качестве сопряженного априорного распределения к нормальному можно выбрать  \n",
    "https://en.wikipedia.org/wiki/Normal-gamma_distribution\n",
    "\n",
    "(если варьировать и $\\mu$, и $\\sigma$).\n",
    "\n",
    "Если только $\\mu$, будет проще - сопряженным априорным распределением также будет нормальное.\n",
    "\n",
    "См. также https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf \n",
    "\n",
    "Про использование NG-модели - см. https://stackoverflow.com/a/53367519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Сравнение двух нормальных распределений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_a = 1.5\n",
    "sigma_a = 0.7\n",
    "mean_b = 5.0\n",
    "sigma_b = 1.0\n",
    "\n",
    "n_samples = 300\n",
    "sample_a = np.random.normal(loc=mean_a, scale=sigma_a, size=n_samples)\n",
    "sample_b = np.random.normal(loc=mean_b, scale=sigma_b, size=n_samples)\n",
    "\n",
    "\n",
    "print('sample_a: ', sample_a[:3], '...')\n",
    "print('exact mean_a: {}, exact sigma_a: {}'.format(mean_a, sigma_a))\n",
    "print('exact mean_b: {}, exact sigma_b: {}'.format(mean_b, sigma_b))\n",
    "display(pd.concat([\n",
    "    pd.Series(sample_a).describe().rename('sample A').to_frame().T,\n",
    "    pd.Series(sample_b).describe().rename('sample B').to_frame().T]))\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(start=-10, stop=10, num=200)\n",
    "ya = stats.norm.pdf(x, loc=mean_a, scale=sigma_a)\n",
    "yb = stats.norm.pdf(x, loc=mean_b, scale=sigma_b)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=sample_a, histnorm='probability density', \n",
    "                           name='Samples A', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Histogram(x=sample_b, histnorm='probability density', \n",
    "                           name='Samples B', marker_color='blue',\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=x, y=ya, name='A', line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=x, y=yb, name='B', line_color='blue'))\n",
    "fig.update_layout(title='Normal Distributions',\n",
    "                  xaxis_title='',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = 1001\n",
    "mean_grid = np.linspace(1, 10, grid_points)\n",
    "mean_grid_prior = [ 1.0 / grid_points for x in mean_grid]\n",
    "grid_points = 101\n",
    "sigma_grid = np.linspace(0.1, 3, grid_points)\n",
    "sigma_grid_prior = [ 1.0 / grid_points for x in sigma_grid]\n",
    "\n",
    "grid = pd.merge(pd.DataFrame({'mean': mean_grid, 'mean_prior': mean_grid_prior, 'tmp_merge_key': 0}),\n",
    "                pd.DataFrame({'sigma': sigma_grid, 'sigma_prior': sigma_grid_prior, 'tmp_merge_key': 0}),\n",
    "                how='outer', \n",
    "                on='tmp_merge_key')\n",
    "grid = grid[['mean', 'sigma', 'mean_prior', 'sigma_prior']]\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['A logprob(data|mean, sigma)'] = grid.apply(\n",
    "    lambda row: np.sum(stats.norm.logpdf(sample_a, loc=row['mean'], scale=row['sigma'])),\n",
    "    axis = 1)\n",
    "grid['A prob(data|mean, sigma)_fromlog'] = grid['A logprob(data|mean, sigma)'].apply('exp')\n",
    "grid['A_posterior'] = grid['A prob(data|mean, sigma)_fromlog'] * grid['mean_prior'] * grid['sigma_prior']\n",
    "grid['A_posterior'] = grid['A_posterior'] / sum(grid['A_posterior'])\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['B logprob(data|mean, sigma)'] = grid.apply(\n",
    "    lambda row: np.sum(stats.norm.logpdf(sample_b, loc=row['mean'], scale=row['sigma'])),\n",
    "    axis = 1)\n",
    "grid['B prob(data|mean, sigma)_fromlog'] = grid['B logprob(data|mean, sigma)'].apply('exp')\n",
    "grid['B_posterior'] = grid['B prob(data|mean, sigma)_fromlog'] * grid['mean_prior'] * grid['sigma_prior']\n",
    "grid['B_posterior'] = grid['B_posterior'] / sum(grid['B_posterior'])\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(max(grid['A prob(data|mean, sigma)_fromlog']))\n",
    "# grid[grid['A_posterior'] > 0.001 ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: avoid overlapping scales\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(z=grid['A_posterior'],\n",
    "                         x=grid['mean'],\n",
    "                         y=grid['sigma'],\n",
    "                         opacity=0.5))\n",
    "fig.add_trace(go.Heatmap(z=grid['B_posterior'],\n",
    "                         x=grid['mean'],\n",
    "                         y=grid['sigma'],\n",
    "                         opacity=0.5))\n",
    "fig.update_layout(title='Posterior Probability Density',\n",
    "                  xaxis_title='Mean',\n",
    "                  yaxis_title='Sigma')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mean_integrated_by_sigma = grid.groupby('mean').agg(lambda z: np.trapz(z['A_posterior'], x=z['sigma'])).iloc[:,0]\n",
    "A_mean_integrated_by_sigma = A_mean_integrated_by_sigma.rename('A_post_integr_over_sigma').reset_index()\n",
    "display(A_mean_integrated_by_sigma.loc[A_mean_integrated_by_sigma['A_post_integr_over_sigma'].idxmax()])\n",
    "\n",
    "B_mean_integrated_by_sigma = grid.groupby('mean').agg(lambda z: np.trapz(z['B_posterior'], x=z['sigma'])).iloc[:,0]\n",
    "B_mean_integrated_by_sigma = B_mean_integrated_by_sigma.rename('B_post_integr_over_sigma').reset_index()\n",
    "display(B_mean_integrated_by_sigma.loc[B_mean_integrated_by_sigma['B_post_integr_over_sigma'].idxmax()])\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=A_mean_integrated_by_sigma['mean'], \n",
    "                         y=A_mean_integrated_by_sigma['A_post_integr_over_sigma'],\n",
    "                         name='Mean A',\n",
    "                         mode='lines+markers'))\n",
    "fig.add_trace(go.Scatter(x=B_mean_integrated_by_sigma['mean'], \n",
    "                         y=B_mean_integrated_by_sigma['B_post_integr_over_sigma'],\n",
    "                         name='Mean B',\n",
    "                         mode='lines+markers'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='mean',\n",
    "                  yaxis_title='Prob',\n",
    "                  hovermode=\"x\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Оценка параметров распределения\n",
    "\n",
    "Из сетки с вероятностями параметров, можно получить оценку на наиболее вероятные значения параметров.\n",
    "Типа, 91-процентный интервал (HPDI) для mu и sigma.\n",
    "\n",
    "Это здорово и увлекательно. Но не то, что нужно.\n",
    "Интересуют не параметры модели, а какое распределение будет давать \"большие\" результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Сравнение распределений\n",
    "\n",
    "Первое - точечные оценки.\n",
    "Т.е. сравнение средней величины и дисперсии в каждом.\n",
    "Считается среднее. Либо аналитически, либо сэмплируется.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Далее смотрится P(A) > P (B) .\n",
    "Это эквивалентно Z = A - B. P(Z) > 0. \n",
    "\n",
    "Т.е. определяется новая случайная величина. Смотрится ее распределение.\n",
    "Она показывает насколько A больше B и с какой вероятностью.\n",
    "Особое внимание на накопленную сумму P(A-B > 0).\n",
    "\n",
    "То же для A / B. см. https://en.wikipedia.org/wiki/Ratio_distribution\n",
    "То же самое. В итоге распределение P(A/B). \n",
    "Обратить внимание на накопленную сумму вероятности P(A/B) > 1. \n",
    "По идее должна совпасть с P(A - B) > 0.\n",
    "С распределением a/b особенность в том, что не определено среднее.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 100000\n",
    "posterior_a = grid['A_posterior']\n",
    "posterior_b = grid['B_posterior']\n",
    "grid_idx = range(0, posterior_a.size)\n",
    "pars_post_sample_a = np.random.choice(grid_idx, size=n_sample, p=posterior_a)\n",
    "pars_post_sample_b = np.random.choice(grid_idx, size=n_sample, p=posterior_b)\n",
    "#use np.map\n",
    "sample_a = [np.random.normal(loc=grid['mean'][i], scale=grid['sigma'][i]) for i in pars_post_sample_a]\n",
    "sample_b = [np.random.normal(loc=grid['mean'][i], scale=grid['sigma'][i]) for i in pars_post_sample_b]\n",
    "z = [b - a for a,b in zip (sample_a, sample_b)]\n",
    "#z\n",
    "c = [b / a for a,b in zip (sample_a, sample_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.array(z)\n",
    "diff = np.linspace(start=0, stop=10, num=100)\n",
    "accum_prob = [len(zz[zz >= x]) / len(zz) for x in diff]\n",
    "\n",
    "print(\"B-A > 0: \", len(zz[zz >= 0]) / len(zz))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=z, histnorm='probability density', \n",
    "                           name='B-A', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=diff, y=accum_prob, name='B-A > x', line_color='red'))\n",
    "\n",
    "fig.update_layout(title='B-A',\n",
    "                  xaxis_title='B-A',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.array(c)\n",
    "frac = np.linspace(start=0.1, stop=10, num=100)\n",
    "accum_prob = [len(cc[cc >= x]) / len(c) for x in frac]\n",
    "\n",
    "print(\"B/A > 1: \", len(cc[cc >= 1]) / len(cc))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=cc, histnorm='probability density', \n",
    "                           name='A/B', marker_color='red',\n",
    "                           xbins=dict(start=-10.0, end=10.0, size=0.3),\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=frac, y=accum_prob, name='B/A > x', line_color='red'))\n",
    "\n",
    "fig.update_layout(title='B/A',\n",
    "                  xaxis_title='B/A',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Зачем нужна модель?\n",
    "Почему бы просто не посчитать распределение разности с помощью ресемплинга?\n",
    "\n",
    "См. permutation test и \n",
    "См. https://arxiv.org/abs/1411.5279 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Сравнить с исходными выборками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rs = 100000\n",
    "diff_rs = np.random.choice(sample_b, n_rs) - np.random.choice(sample_a, n_rs)\n",
    "diff_grid_rs = np.linspace(start=0, stop=10, num=100)\n",
    "accum_prob_rs = [len(diff_rs[diff_rs >= x]) / len(diff_rs) for x in diff_grid_rs]\n",
    "\n",
    "print(\"rs B-A > 0: \", len(diff_rs[diff_rs >= 0]) / len(diff_rs))\n",
    "print(\"B-A > 0: \", len(zz[zz >= 0]) / len(zz))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=diff_rs, histnorm='probability density', \n",
    "                           name='B-A', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=diff_grid_rs, y=accum_prob_rs, name='B-A > x', line_color='red'))\n",
    "\n",
    "fig.add_trace(go.Histogram(x=z, histnorm='probability density', \n",
    "                           name='B-A', marker_color='blue',\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=diff, y=accum_prob, name='B-A > x', line_color='blue'))\n",
    "\n",
    "\n",
    "fig.update_layout(title='B-A',\n",
    "                  xaxis_title='B-A',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rs = 100000\n",
    "rat_rs = np.random.choice(sample_b, n_rs) / np.random.choice(sample_a, n_rs)\n",
    "rat_grid_rs = np.linspace(start=0.1, stop=10, num=100)\n",
    "rat_accum_prob_rs = [len(rat_rs[rat_rs >= x]) / len(rat_rs) for x in rat_grid_rs]\n",
    "\n",
    "print(\"rs B/A > 1: \", len(rat_rs[rat_rs >= 0]) / len(rat_rs))\n",
    "print(\"B/A > 1: \", len(cc[cc >= 1]) / len(cc))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=rat_rs, histnorm='probability density', \n",
    "                           name='B/A', marker_color='red',\n",
    "                           xbins=dict(start=-10.0, end=10.0, size=0.3),\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=rat_grid_rs, y=rat_accum_prob_rs, name='B/A > 1', line_color='red'))\n",
    "\n",
    "fig.add_trace(go.Histogram(x=cc, histnorm='probability density', \n",
    "                           name='A/B', marker_color='blue',\n",
    "                           xbins=dict(start=-10.0, end=10.0, size=0.3),\n",
    "                           opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=frac, y=accum_prob, name='B/A > x', line_color='blue'))\n",
    "\n",
    "\n",
    "fig.update_layout(title='B/A',\n",
    "                  xaxis_title='B/A',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "На глаз не отличишь.\n",
    "Тогда зачем все-таки нужна модель?\n",
    "\n",
    "С моделью проще что-то делать аналитически ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Зависимость от размера выборки\n",
    "\n",
    "Исходный пример - много точек и заведомо видимое различие.\n",
    "\n",
    "Отдельно - построить зависимость P(Z > 0) в зависимости от размера выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_a = 1.5\n",
    "sigma_a = 0.7\n",
    "mean_b = mean_a * 1.3\n",
    "sigma_b = sigma_a * 1.5\n",
    "\n",
    "n_rs = 100000\n",
    "diff_grid_rs = np.linspace(start=0, stop=10, num=100)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for n_samples, col in zip([30, 100, 300, 1000, 3000, 10000], [\"red\", \"green\", \"blue\", \"orange\", \"cyan\", \"black\"]):\n",
    "    sample_a_diffn = np.random.normal(loc=mean_a, scale=sigma_a, size=n_samples)\n",
    "    sample_b_diffn = np.random.normal(loc=mean_b, scale=sigma_b, size=n_samples)\n",
    "\n",
    "    diff_rs = np.random.choice(sample_b_diffn, n_rs) - np.random.choice(sample_a_diffn, n_rs)\n",
    "    accum_prob_rs = [len(diff_rs[diff_rs >= x]) / len(diff_rs) for x in diff_grid_rs]\n",
    "\n",
    "    print(\"rs B-A > 0: \", len(diff_rs[diff_rs >= 0]) / len(diff_rs))\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=diff_rs, histnorm='probability density', \n",
    "                           name=str(n_samples), marker_color=col,\n",
    "                           opacity=0.3))\n",
    "    fig.add_trace(go.Scatter(x=diff_grid_rs, y=accum_prob_rs, name=str(n_samples), line_color=col))\n",
    "\n",
    "\n",
    "fig.update_layout(title='B-A',\n",
    "                  xaxis_title='B-A',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Как выбрать один из вариантов \n",
    "\n",
    "Можно ли быть уверенным, что результат получился не случайно?\n",
    "\n",
    "Если повторить эксперимент несколько раз, как будет меняться оценка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(x>y | data) = P(data | x>y) * P(x>y) / P(data) ?\n",
    "\n",
    "P(A-B > x | data) = P(data | A-B > x) * P(A-B > x) / P(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Длительность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Предположим, что угадали параметры распределения в каждой из групп.  \n",
    "Можно семлпировать значения из него.  \n",
    "(вернее, семплировать все постериорное распределение).  \n",
    "До тех пор, пока неопределенность не снизится до нужного уровня.  \n",
    "Зная приток трафика, можно пересчитать это значение в количество дней. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример на искусственных данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Смоделировать чеки и LTV с помощью распределения Паретто или BuyTillYouDie. \n",
    "\n",
    "Потом - понять как оценивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pareto pdf = b / x^(b+1), b>0, x>=1\n",
    "# lomax pdf = c / (x+1)^c, c>0, x>=1 (pareto with loc=-1)\n",
    "b = 1.16\n",
    "pareto_x = np.linspace(1, 5, 100)\n",
    "lomax_x = np.linspace(0, 5, 100)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=pareto_x, y=stats.pareto.pdf(pareto_x, b), name='pareto pdf'))\n",
    "fig.add_trace(go.Scatter(x=lomax_x, y=stats.lomax.pdf(lomax_x, b), name='lomax'))\n",
    "fig.add_trace(go.Scatter(x=lomax_x, y=stats.pareto.pdf(lomax_x, b, loc=-1), name='pareto loc'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моделирование отдельных покупок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buy Till You Die - Класс моделей для моделирования отдельных покупок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cran.r-project.org/web/packages/BTYD/vignettes/BTYD-walkthrough.pdf?source=post_page\n",
    "\n",
    "https://en.wikipedia.org/wiki/Buy_Till_you_Die"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
